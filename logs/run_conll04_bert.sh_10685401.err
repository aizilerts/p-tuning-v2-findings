Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
[INFO|configuration_utils.py:583] 2025-06-17 15:47:56,242 >> loading configuration file https://huggingface.co/bert-large-uncased/resolve/main/config.json from cache at /u/achen12/.cache/huggingface/transformers/1cf090f220f9674b67b3434decfe4d40a6532d7849653eac435ff94d31a4904c.1d03e5e4fa2db2532c517b2cd98290d8444b237619bd3d2039850a6d5e86473d
[INFO|configuration_utils.py:620] 2025-06-17 15:47:56,243 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|configuration_utils.py:583] 2025-06-17 15:47:56,348 >> loading configuration file https://huggingface.co/bert-large-uncased/resolve/main/config.json from cache at /u/achen12/.cache/huggingface/transformers/1cf090f220f9674b67b3434decfe4d40a6532d7849653eac435ff94d31a4904c.1d03e5e4fa2db2532c517b2cd98290d8444b237619bd3d2039850a6d5e86473d
[INFO|configuration_utils.py:620] 2025-06-17 15:47:56,349 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|tokenization_utils_base.py:1741] 2025-06-17 15:47:56,719 >> loading file https://huggingface.co/bert-large-uncased/resolve/main/vocab.txt from cache at /u/achen12/.cache/huggingface/transformers/e12f02d630da91a0982ce6db1ad595231d155a2b725ab106971898276d842ecc.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1741] 2025-06-17 15:47:56,719 >> loading file https://huggingface.co/bert-large-uncased/resolve/main/tokenizer.json from cache at /u/achen12/.cache/huggingface/transformers/475d46024228961ca8770cead39e1079f135fd2441d14cf216727ffac8d41d78.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|tokenization_utils_base.py:1741] 2025-06-17 15:47:56,720 >> loading file https://huggingface.co/bert-large-uncased/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1741] 2025-06-17 15:47:56,720 >> loading file https://huggingface.co/bert-large-uncased/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1741] 2025-06-17 15:47:56,720 >> loading file https://huggingface.co/bert-large-uncased/resolve/main/tokenizer_config.json from cache at /u/achen12/.cache/huggingface/transformers/300ecd79785b4602752c0085f8a89c3f0232ef367eda291c79a5600f3778b677.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed
[INFO|configuration_utils.py:583] 2025-06-17 15:47:56,811 >> loading configuration file https://huggingface.co/bert-large-uncased/resolve/main/config.json from cache at /u/achen12/.cache/huggingface/transformers/1cf090f220f9674b67b3434decfe4d40a6532d7849653eac435ff94d31a4904c.1d03e5e4fa2db2532c517b2cd98290d8444b237619bd3d2039850a6d5e86473d
[INFO|configuration_utils.py:620] 2025-06-17 15:47:56,812 >> Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

  0%|          | 0/3 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/projects/beqy/achen12/P-tuning-v2/run.py", line 121, in <module>
    trainer, predict_dataset = get_trainer(args)
  File "/projects/beqy/achen12/P-tuning-v2/tasks/ner/get_trainer.py", line 38, in get_trainer
    dataset = NERDataset(tokenizer, data_args, training_args)
  File "/projects/beqy/achen12/P-tuning-v2/tasks/ner/dataset.py", line 14, in __init__
    load_dataset('/projects/beqy/achen12/P-tuning-v2/tasks/ner/datasets/conll2004.py') # FOR TESTING CONLL2004 ONLY
  File "/u/achen12/miniconda3/envs/pt2/lib/python3.8/site-packages/datasets/load.py", line 1632, in load_dataset
    builder_instance.download_and_prepare(
  File "/u/achen12/miniconda3/envs/pt2/lib/python3.8/site-packages/datasets/builder.py", line 607, in download_and_prepare
    self._download_and_prepare(
  File "/u/achen12/miniconda3/envs/pt2/lib/python3.8/site-packages/datasets/builder.py", line 675, in _download_and_prepare
    split_generators = self._split_generators(dl_manager, **split_generators_kwargs)
  File "/u/achen12/.cache/huggingface/modules/datasets_modules/datasets/conll2004/c926facc6ccea37a9b5daf48f595e2d778ff4297de107915d4caabb5775e9b0a/conll2004.py", line 101, in _split_generators
    downloaded_files = dl_manager.download_and_extract(urls_to_download)
  File "/u/achen12/miniconda3/envs/pt2/lib/python3.8/site-packages/datasets/utils/download_manager.py", line 284, in download_and_extract
    return self.extract(self.download(url_or_urls))
  File "/u/achen12/miniconda3/envs/pt2/lib/python3.8/site-packages/datasets/utils/download_manager.py", line 196, in download
    downloaded_path_or_paths = map_nested(
  File "/u/achen12/miniconda3/envs/pt2/lib/python3.8/site-packages/datasets/utils/py_utils.py", line 216, in map_nested
    mapped = [
  File "/u/achen12/miniconda3/envs/pt2/lib/python3.8/site-packages/datasets/utils/py_utils.py", line 217, in <listcomp>
    _single_map_nested((function, obj, types, None, True))
  File "/u/achen12/miniconda3/envs/pt2/lib/python3.8/site-packages/datasets/utils/py_utils.py", line 152, in _single_map_nested
    return function(data_struct)
  File "/u/achen12/miniconda3/envs/pt2/lib/python3.8/site-packages/datasets/utils/download_manager.py", line 217, in _download
    return cached_path(url_or_filename, download_config=download_config)
  File "/u/achen12/miniconda3/envs/pt2/lib/python3.8/site-packages/datasets/utils/file_utils.py", line 312, in cached_path
    raise FileNotFoundError("Local file {} doesn't exist".format(url_or_filename))
FileNotFoundError: Local file /projects/beqy/achen12/P-tuning-v2/tasks/ner/datasets/../../../data/CoNLL04/train.txt doesn't exist
  0%|          | 0/3 [00:00<?, ?it/s]